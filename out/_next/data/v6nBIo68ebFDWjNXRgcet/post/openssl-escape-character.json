{"pageProps":{"frontmatter":{"title":"Openssl escape character","date":"January 8, 2022","description":"Be careful about the escape character as Linux input"},"post":{"content":" \nFirst of all, I pick [HTTP signature](https://datatracker.ietf.org/doc/html/draft-cavage-http-signatures-12) as my authorization method.\n\nI use [Vegeta](https://github.com/tsenart/vegeta) to load test my API service.\n\nWhen writing a script for target generation, I need to make a signature for each request.\n\nSo I used `openssl` to generate it.\n```\necho -n \"${message}\" | openssl dst -sha256 -hmac -binary | base64\n```\nBut I did not pass my authenticator.\n\nAfter some trying(use other language to reproduce what happened), I found that message used for generation was weird.(check the byte)\n\nGo:\n```go\nimport (\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\tb64 \"encoding/base64\"\n)\n// https://go.dev/play/p/JaDyZh_wNqn\nfunc hmacSha256(data string, secret string) string {\n\th := hmac.New(sha256.New, []byte(secret))\n\th.Write([]byte(data))\n\treturn b64.URLEncoding.EncodeToString(h.Sum(nil))\n}\n```\n\nNode:\n```javascript\nvar crypto = require('crypto');\nfunction hmacSha256(message, secret) {\n    hmac = crypto.createHmac('sha256', secret);\n    hmac.update(message);\n    return hmac.digest('base64')\n}\n```\n\nWhen make `a\\nmessage` as argument in Linux, it would be the same as `a\\\\nmessage`.\n\nThis was why my target generation script didn't pass the authenticator.\n\nI had definitely known how the escape character works, but I didn't check it in the first place.\n\nWhen using escape character as Linux input, you should be careful about it.\n\nOpenssl might be a misplace but never mind. I found the problem from it.\n\nJust write a note to remember the time wasted on it.","excerpt":""},"previousPost":{"slug":"cache-policy","frontmatter":{"title":"An introduction to Window TinyLFU","date":"April 27, 2021","description":"TinyLFU is a frequency-based cache admission policy"},"excerpt":"","content":" \n## Foreword\nI will just easily go through techniques used by Window TinyLFU.\n\n## Why Cache?\nBecause we want to access data fast. The buffering provided by a cache benefits both latency and throughput.\n\n## Eviction Policies\n- Since we cannot cache all data we have, we need to discard some cache when out of space\n- We should consider what the cost is if we choose the policy\n- Eviction decisions should be done in an efficient manner, in order to avoid a situation in which the computation and space overheads required to answer these questions surpasses the benefit of using the cache\n- Hit rate, latency & space matter\n\n#### Examples\n- Least recently used (LRU): Discards the least recently used items first\n- Least frequently used (LFU): Discards data that was least frequently used\n- Segment LRU (SLRU):\n  - SLRU cache is divided into two segments, a probationary segment and a\nprotected segment\n  - Lines in each segment are ordered from the most to the least recently\naccessed\n  - Data from misses is added to the cache at the most recently accessed end of\nthe probationary segment\n  - Hits are removed from wherever they currently reside and added to the most\nrecently accessed end of the protected segment\n  - Lines in the protected segment have thus been accessed at least twice\n\n## Probability data structure\n\n#### Examples\n- Bloom Filter\n  - Pairwise independent hash functions\n  - Used to test whether an element is a member of a set\n  - Two result: \"possibly in set\" or \"definitely not in set\"\n  - isInSet(input) = (h1(input) and h2(input) and h3(input) ...)\n- Count-min Sketch\n  - Pairwise independent hash functions\n  - Used to count elements\n  - count(input) = min(h1(input), h2(input), h3(input), ...)\n\n## Admission policy\n- Hope to boost the effectiveness of caches\n- Given a newly accessed item and an eviction candidate from the cache, our\nscheme decides, based on the recent access history, whether it is worth\nadmitting the new item into the cache at the expense of the eviction candidate\n- An accessed item is only inserted into the cache if an admission policy\ndecides that the cache hit ratio is likely to benefit from replacing it with the\ncache victim\n\n### TinyLFU\nTinyLFU admission policy use Bloom Filter and Count-min Sketch to trace state of elements.\n![TinyLFU structure](cache-policy-pics/tinylfu.png)\n\nIf there is a new element insert event that makes the main cache(SLRU) discard its element, they will be compared with the\nstate of TinyLFU admission policy (Bloom Filter and Count-min Sketch).\n![TinyLFU with Main Cache](cache-policy-pics/tinylfu-2.png)\n\nFinally, for sparse bursts, the paper suggest a LRU as window cache.\n![W-TinyLFU](cache-policy-pics/w-tinylfu.png)\n\n## Reference\n- [Cache(wikipedia)](https://en.wikipedia.org/wiki/Cache_(computing))\n- [Cache replacement policies](https://en.wikipedia.org/wiki/Cache_replacement_policies)\n- [Caffeine wiki](https://github.com/ben-manes/caffeine/wiki/Efficiency)\n- [Window TinyLFU paper](https://dl.acm.org/doi/10.1145/3149371)"},"nextPost":null},"__N_SSG":true}