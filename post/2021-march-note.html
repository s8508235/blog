<!DOCTYPE html><html lang="zh-TW"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');if("system"===e||(!e&&true)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><title>2021 March note | s8508235&#x27;s blog</title><meta name="description" content="webrtc/linux/network reading"/><meta property="og:type" content="website"/><meta name="og:title" property="og:title" content="2021 March note"/><meta name="og:description" property="og:description" content="webrtc/linux/network reading"/><link rel="icon" type="image/png" href="/blog/favicon.ico"/><link rel="apple-touch-icon" href="/blog/favicon.ico"/><meta name="next-head-count" content="10"/><link rel="preload" href="/_next/static/css/4fc286d84d344085.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4fc286d84d344085.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-24fda4117f092221.js" defer=""></script><script src="/_next/static/chunks/main-eea31613c344d1ea.js" defer=""></script><script src="/_next/static/chunks/pages/_app-492e99d0a17aabe9.js" defer=""></script><script src="/_next/static/chunks/827-22efc97fb31500a7.js" defer=""></script><script src="/_next/static/chunks/716-a52d3c0d45b6ee73.js" defer=""></script><script src="/_next/static/chunks/552-14dffc3b36c9d95b.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-8fb7f12603d96f88.js" defer=""></script><script src="/_next/static/5rHCI8A1s62P7WZFUzuaq/_buildManifest.js" defer=""></script><script src="/_next/static/5rHCI8A1s62P7WZFUzuaq/_ssgManifest.js" defer=""></script><script src="/_next/static/5rHCI8A1s62P7WZFUzuaq/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div class="w-full min-h-screen dark:bg-gray-700 dark:text-white"><div class="max-w-screen-sm px-4 py-12 mx-auto antialiased font-body"><header class="flex items-center justify-between  mb-2"><div class="max-w-md"><h1><a class="text-2xl font-black text-blue-800 no-underline font-display dark:text-blue-400" href="/">Minimal blog</a></h1></div></header><main><article><header class="mb-8"><h1 class="mb-2 text-5xl font-black leading-none font-display">2021 March note</h1><p class="text-sm">March 27, 2021</p></header><div class="mb-4 prose lg:prose-lg dark:prose-dark"><h2>聲明</h2><p>我想筆記摘要是作給未來的自己用的，不過如果剛好有人看到我的筆記去讀原文的話，那是再好不過。<del>有人只看筆記不看課本的嗎</del></p><p>如果有錯也歡迎糾正，謝謝指教。</p><h2>Reading</h2><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://dev.to/lazerwalker/why-video-chat-is-a-hard-technical-problem-43gj">Why video chat is a hard technical problem</a></p><ul><li>本文主要是開發 webrtc 會遇到的問題</li><li>瀏覽器支援不一</li><li>需要自己的後端並且可能需要面對過多 peer to peer 連線 ( Websocket -&gt; STUN -&gt; SFU)</li><li>應該也是因為這樣才會有第三方 SDK 在做這些事情吧</li></ul></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://hkt999.medium.com/tls-1-3-quic-%E8%88%87-http-3-%E5%B0%8D%E6%95%88%E8%83%BD%E7%9A%84%E6%94%B9%E5%96%84-a37b2ddcfc95">TLS 1.3 / QUIC 與 HTTP/3 對效能的改善</a></p><ul><li>本文主要是 QUIC 介紹</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.igvita.com/2012/07/19/latency-the-new-web-performance-bottleneck">latency</a> 影響</li><li>基於 UDP</li><li>TLS 1.3 的 handshake 會先 Client HELLO (CHLO) 來節省 RTT</li><li>QUIC 的 handshake 類似 TLS 1.3 ( inchoate CHLO 似乎有可能一次傳不完)</li><li>解決 TCP retransmission ambiguity problem</li><li>這個<a target="_blank" rel="noopener noreferrer" href="https://www.uio.no/studier/emner/matnat/ifi/INF5072/v18/2018_jan25_quic_sferlin.pdf">pdf</a>有詳盡的介紹</li></ul></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/CAFxX/571a1558db9a7b393579">Persistent &quot;pipes&quot; in Linux</a></p><ul><li>persistent pipe (<a target="_blank" rel="noopener noreferrer" href="https://man7.org/linux/man-pages/man2/pipe.2.html">pipe</a> 為 Linux 重新導向資料的方法)</li><li>hole punching 為 Linux <a target="_blank" rel="noopener noreferrer" href="javascript:void(0)">fallocate</a> 提供的特性，可以標注一個檔案哪段不要 (the logical size of the file does not change; only the physical size (the number of blocks) may change)</li><li>利用這個特性把檔案當作 queue 來使用且 lseek 可以跳過 hole</li></ul></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03">Why kafka is so fast</a></p><ul><li>實時並不代表快，而是可預測</li><li>針對吞吐量去最佳化</li><li>log-structured -&gt; append-only log -&gt; sequential 很多系統也都採用，有興趣可參考<a target="_blank" rel="noopener noreferrer" href="https://www.databass.dev">此書</a></li><li>record batch 像 <a target="_blank" rel="noopener noreferrer" href="https://redis.io/topics/pipelining">redis pipeline</a> 一樣，遇到網路問題的話還是要為了減少 RTT 還做 batch</li><li>cheap consumers 不移除 message 而是增加 offset，並依靠之前的 sequential read</li><li>unflushed buffered writes 不會 fsync -&gt; <br/>disk-backed in-memory queue -&gt;<br/>一個 ack 的 write 並不代表 durability -&gt;<br/>用 replica 來 cover</li><li></li></ul></li><li><p>RCU</p><ul><li><a target="_blank" rel="noopener noreferrer" href="https://hackmd.io/@sysprog/linux-rcu">Linux 核心設計: RCU 同步機制</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://lwn.net/Articles/262464/">What is RCU, Fundamentally?</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://lwn.net/Articles/263130/">What is RCU? Part 2: Usage</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://lwn.net/Articles/264090/">RCU part 3: the RCU API</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.huaweicloud.com/articles/74854d8cc300d73a76b7b526044f6709.html">Linux中的RCU的那點事</a></li><li>one writer multiple readers. mainly require 3 mechanisms to implement it.<ol><li>Publish-Subscribe Mechanism (insertion)</li><li>Wait For Pre-Existing RCU Readers to Complete (deletion)</li><li>Maintain Multiple Versions of Recently Updated Objects (reader update)</li></ol></li><li>RCU 並不保證一定能讀到新增的節點或不讀到要被刪除的節點 (grace period)</li><li>RCU 讓 reader 不需要 lock 和不需要擔心 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Memory_barrier">memory barrier</a> (為了 instruction pipeline 效能提昇而讓 instruction 亂序執行， memory barrier 是為了避免亂序而使用) 且有不錯的效能</li></ul></li></ul></div><hr class="mt-4"/><footer><div class="flex items-center space-x-3 mt-8 mb-16"><div class="flex-shrink-0 mb-0 overflow-hidden rounded-full w-14 h-14"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2756%27%20height=%2756%27/%3e"/></span><img alt="Profile" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;filter:blur(20px);background-size:cover;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAAAAAAQMlOCAAAASklEQVR42gE/AMD/AG/Q1dbUplpPAKD/7eHs1QBBAKD85tivzKBnAIbs7eDW3/ClAIvJyODi3ue9ACmwueTk4ejCACBf19TX1N6z530ojUkGi+cAAAAASUVORK5CYII=&quot;);background-position:0% 0%"/><noscript><img alt="Profile" srcSet="https://s8508235.github.io/blog/_next/static/media/profile.7ee99ab4.png?auto=format&amp;fit=max&amp;w=64 1x, https://s8508235.github.io/blog/_next/static/media/profile.7ee99ab4.png?auto=format&amp;fit=max&amp;w=128 2x" src="https://s8508235.github.io/blog/_next/static/media/profile.7ee99ab4.png?auto=format&amp;fit=max&amp;w=128" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p class="text-base leading-7">Written by<!-- --> <a class="font-semibold" target="_blank" rel="noreferrer noopener" href="https://github.com/s8508235">s8508235</a> <b>[ZH-TW/EN]</b><br/>Before being good at writing, I have to start writing.<!-- --> </p></div></footer></article><nav class="flex flex-wrap justify-between mb-10"><a class="text-lg font-bold" href="/post/limit-program-resource">← <!-- -->使用 cgroups 來限制資源</a><a class="text-lg font-bold" href="/post/cache-policy">An introduction to Window TinyLFU<!-- --> →</a></nav></main><footer class="text-lg font-light">© <!-- -->2022<!-- --> If you have any questions, please send me <a href="mailto:a8508235@gmail.com">an email</a>!</footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"2021 March note","date":"March 27, 2021","description":"webrtc/linux/network reading"},"post":{"content":" \n## 聲明\n我想筆記摘要是作給未來的自己用的，不過如果剛好有人看到我的筆記去讀原文的話，那是再好不過。\u003cdel\u003e有人只看筆記不看課本的嗎\u003c/del\u003e\n\n如果有錯也歡迎糾正，謝謝指教。\n\n## Reading\n- [Why video chat is a hard technical problem](https://dev.to/lazerwalker/why-video-chat-is-a-hard-technical-problem-43gj)\n  - 本文主要是開發 webrtc 會遇到的問題\n  - 瀏覽器支援不一\n  - 需要自己的後端並且可能需要面對過多 peer to peer 連線 ( Websocket -\u003e STUN -\u003e SFU)\n  - 應該也是因為這樣才會有第三方 SDK 在做這些事情吧\n- [TLS 1.3 / QUIC 與 HTTP/3 對效能的改善](https://hkt999.medium.com/tls-1-3-quic-%E8%88%87-http-3-%E5%B0%8D%E6%95%88%E8%83%BD%E7%9A%84%E6%94%B9%E5%96%84-a37b2ddcfc95)\n  - 本文主要是 QUIC 介紹\n  - [latency](https://www.igvita.com/2012/07/19/latency-the-new-web-performance-bottleneck) 影響\n  - 基於 UDP\n  - TLS 1.3 的 handshake 會先 Client HELLO (CHLO) 來節省 RTT\n  - QUIC 的 handshake 類似 TLS 1.3 ( inchoate CHLO 似乎有可能一次傳不完)\n  - 解決 TCP retransmission ambiguity problem\n  - 這個[pdf](https://www.uio.no/studier/emner/matnat/ifi/INF5072/v18/2018_jan25_quic_sferlin.pdf)有詳盡的介紹\n\n- [Persistent \"pipes\" in Linux](https://gist.github.com/CAFxX/571a1558db9a7b393579)\n  - persistent pipe ([pipe](https://man7.org/linux/man-pages/man2/pipe.2.html) 為 Linux 重新導向資料的方法) \n  - hole punching 為 Linux [fallocate](https要://man7.org/linux/man-pages/man2/fallocate.2.html) 提供的特性，可以標注一個檔案哪段不要 (the logical size of the file does not change; only the physical size (the number of blocks) may change)\n  - 利用這個特性把檔案當作 queue 來使用且 lseek 可以跳過 hole\n\n- [Why kafka is so fast](https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03)\n  - 實時並不代表快，而是可預測\n  - 針對吞吐量去最佳化\n  - log-structured -\u003e append-only log -\u003e sequential 很多系統也都採用，有興趣可參考[此書](https://www.databass.dev)\n  - record batch 像 [redis pipeline](https://redis.io/topics/pipelining) 一樣，遇到網路問題的話還是要為了減少 RTT 還做 batch\n  - cheap consumers 不移除 message 而是增加 offset，並依靠之前的 sequential read\n  - unflushed buffered writes 不會 fsync -\u003e \\\n  disk-backed in-memory queue -\u003e\\\n  一個 ack 的 write 並不代表 durability -\u003e\\\n  用 replica 來 cover\n  - \n- RCU\n  - [Linux 核心設計: RCU 同步機制](https://hackmd.io/@sysprog/linux-rcu)\n  - [What is RCU, Fundamentally?](http://lwn.net/Articles/262464/)\n  - [What is RCU? Part 2: Usage](https://lwn.net/Articles/263130/)\n  - [RCU part 3: the RCU API](https://lwn.net/Articles/264090/)\n  - [Linux中的RCU的那點事](https://www.huaweicloud.com/articles/74854d8cc300d73a76b7b526044f6709.html)\n  -  one writer multiple readers. mainly require 3 mechanisms to implement it.\n        1. Publish-Subscribe Mechanism (insertion)\n        1. Wait For Pre-Existing RCU Readers to Complete (deletion)\n        1. Maintain Multiple Versions of Recently Updated Objects (reader update)\n  - RCU 並不保證一定能讀到新增的節點或不讀到要被刪除的節點 (grace period)\n  - RCU 讓 reader 不需要 lock 和不需要擔心 [memory barrier](https://en.wikipedia.org/wiki/Memory_barrier) (為了 instruction pipeline 效能提昇而讓 instruction 亂序執行， memory barrier 是為了避免亂序而使用) 且有不錯的效能","excerpt":""},"previousPost":{"slug":"limit-program-resource","frontmatter":{"title":"使用 cgroups 來限制資源","date":"November 20, 2020","description":"cgroups 是 control groups，為 linux 核心的一個功能"},"excerpt":"","content":"\n來限制 memory 來簡單示範一下 cgroups\n\n### Disclaimer\n我不知道這是不是正確的作法，因為從 docker 得到了 cgroups 相關知識，用來這邊，那麼進入正文\n\n---\n### Installation\n```\napt install cgroup-tools\n```\n\nor\n``` \nyum install libcgroup\nyum install libcgroup-tools\n```\n### 建立 cgroup\n\n```cgcreate  -g subsystems:path``` \u003cdel\u003e詳情請洽 red hat 官網\u003c/del\u003e\n\n關於 subsystem 也可以去 `/sys/fs/cgroup` 下面看內建的\n\n也會看到其他教學是直接在 `/sys/fs/cgroup/` 下直接加資料夾，也會自動幫你加完相關檔案\n\n```\nsudo cgcreate -g memory:/mem_test\n```\n\n### 增加限制\n\n可以看到在新增 cgroup 後，可以發現 `/sys/fs/cgroup/memory/memory_test` 下面多了一些檔案\n\n這邊主要看 `memory.limit_in_bytes` 和 `memory.usage_in_bytes` 就好，\n\n用 \n```\ncat /sys/fs/cgroup/memory/memory_test/memory.limit_in_bytes\n``` \n或 \n```\ncgget -g memory:mem_test | grep memory.limit_in_bytes\n``` \n來查看設定，接著是用 \n```\ncgset -r memory.limit_in_bytes=100G mem_test\n``` \n\u003cdel\u003e為什麼這邊不一樣啊! \u003csmall\u003e如果沒有變的話就加上 sudo \u003c/small\u003e\u003c/del\u003e\n\n### 執行程式\n\n`cgexec -g memory:/mem_test command [argument]`\n\n例如:\n```\ncgexec -g memory:/mem_test ping 8.8.8.8\n```\n\n### 觀察\n\n可以使用以下指令來看在這個 cgroup 執行的 process\n```\nsystemd-cgls memory:/mem_test\n``` \n\n看在 cgroup 使用的 memory \u003cdel\u003e應該有更好的方法，歡迎提供\u003c/del\u003e\n\n```\nwatch -n 1 \"cgget -g memory:mem_test | grep memory.usage_in_bytes\"\n``` \n\n\n### 刪除 cgroup\n\n```\nsudo cgdelete memory:/mem_test\n```\n\n### Conclusion\n\n這樣就完成簡單的限制資源，還有其他 subsystem ( cpu, blkio, devices 等等) 可以實作，也可以互相組合，雖然是被大量應用在各種容器技術中，但也是可以簡單拿出來用用看。\u003cdel\u003e大概吧\u003c/del\u003e\n\n### Reference\n- [Red hat Resource management Chapter 2](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch-using_control_groups)"},"nextPost":{"slug":"cache-policy","frontmatter":{"title":"An introduction to Window TinyLFU","date":"April 27, 2021","description":"TinyLFU is a frequency-based cache admission policy"},"excerpt":"","content":" \n## Foreword\nI will just easily go through techniques used by Window TinyLFU.\n\n## Why Cache?\nBecause we want to access data fast. The buffering provided by a cache benefits both latency and throughput.\n\n## Eviction Policies\n- Since we cannot cache all data we have, we need to discard some cache when out of space\n- We should consider what the cost is if we choose the policy\n- Eviction decisions should be done in an efficient manner, in order to avoid a situation in which the computation and space overheads required to answer these questions surpasses the benefit of using the cache\n- Hit rate, latency \u0026 space matter\n\n#### Examples\n- Least recently used (LRU): Discards the least recently used items first\n- Least frequently used (LFU): Discards data that was least frequently used\n- Segment LRU (SLRU):\n  - SLRU cache is divided into two segments, a probationary segment and a\nprotected segment\n  - Lines in each segment are ordered from the most to the least recently\naccessed\n  - Data from misses is added to the cache at the most recently accessed end of\nthe probationary segment\n  - Hits are removed from wherever they currently reside and added to the most\nrecently accessed end of the protected segment\n  - Lines in the protected segment have thus been accessed at least twice\n\n## Probability data structure\n\n#### Examples\n- Bloom Filter\n  - Pairwise independent hash functions\n  - Used to test whether an element is a member of a set\n  - Two result: \"possibly in set\" or \"definitely not in set\"\n  - isInSet(input) = (h1(input) and h2(input) and h3(input) ...)\n- Count-min Sketch\n  - Pairwise independent hash functions\n  - Used to count elements\n  - count(input) = min(h1(input), h2(input), h3(input), ...)\n\n## Admission policy\n- Hope to boost the effectiveness of caches\n- Given a newly accessed item and an eviction candidate from the cache, our\nscheme decides, based on the recent access history, whether it is worth\nadmitting the new item into the cache at the expense of the eviction candidate\n- An accessed item is only inserted into the cache if an admission policy\ndecides that the cache hit ratio is likely to benefit from replacing it with the\ncache victim\n\n### TinyLFU\nTinyLFU admission policy use Bloom Filter and Count-min Sketch to trace state of elements.\n![TinyLFU structure](cache-policy-pics/tinylfu.png)\n\nIf there is a new element insert event that makes the main cache(SLRU) discard its element, they will be compared with the\nstate of TinyLFU admission policy (Bloom Filter and Count-min Sketch).\n![TinyLFU with Main Cache](cache-policy-pics/tinylfu-2.png)\n\nFinally, for sparse bursts, the paper suggest a LRU as window cache.\n![W-TinyLFU](cache-policy-pics/w-tinylfu.png)\n\n## Reference\n- [Cache(wikipedia)](https://en.wikipedia.org/wiki/Cache_(computing))\n- [Cache replacement policies](https://en.wikipedia.org/wiki/Cache_replacement_policies)\n- [Caffeine wiki](https://github.com/ben-manes/caffeine/wiki/Efficiency)\n- [Window TinyLFU paper](https://dl.acm.org/doi/10.1145/3149371)"}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2021-march-note"},"buildId":"5rHCI8A1s62P7WZFUzuaq","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>